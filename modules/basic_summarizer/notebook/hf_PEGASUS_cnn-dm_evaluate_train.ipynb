{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PEGASUS\n",
    "+ 使用 cnn dailymail 通过 PEGASUS 进行模型效果评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Found cached dataset cnn_dailymail (C:/Users/Administrator/.cache/huggingface/datasets/cnn_dailymail/default/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4827fff39f6142c1a15e34e0fa7b6853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['article', 'highlights', 'id']\n"
     ]
    }
   ],
   "source": [
    "# 代理必须关闭\n",
    "# hide_output\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\",version=\"3.0.0\")\n",
    "print(f\"Features: {dataset['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Article (excerpt of 500 characters, total length: 4051):\n",
      "\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most s\n",
      "\n",
      "Summary (length: 281):\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[\"train\"][1]\n",
    "print(f\"\"\"\n",
    "Article (excerpt of 500 characters, total length: {len(sample[\"article\"])}):\n",
    "\"\"\")\n",
    "print(sample[\"article\"][:500])\n",
    "print(f'\\nSummary (length: {len(sample[\"highlights\"])}):')\n",
    "print(sample[\"highlights\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During the calm voyage under the sea, Werner fell asleep. I dont know how long it took him to wake up after being pushed by Hopkins. He looked at the chart and track on the small screen and found that two thirds of the voyage had gone, and it seemed that there was nothing unusual. Hopkins asked him to pay attention. He heard the voice of a ship sailing on the sea. He had seen it through the sky during the previous voyage. He looked at Hopkins in puzzlement. But after listening, he knew that something was wrong: different from before, the size of the voice did not change this time\n"
     ]
    }
   ],
   "source": [
    "sample_text = dataset[\"train\"][1][\"article\"][:2000]\n",
    "sample_text = '在海下平静的航程中，沃纳睡着了。不知过了多长时间，他被霍普金斯推醒，他看看小屏幕上的海图和航迹，发现航程已走了三分之二，似乎没有什么异常。霍普金斯让他注意听，他听到了一艘海面航船的声音，在以前的航程中这已司空见贯，他不解地看看霍普金斯。但接着听下去，他知道事情不对：与以前不同，这次声音的大小没有变化。'\n",
    "sample_text = 'During the calm voyage under the sea, Werner fell asleep. I dont know how long it took him to wake up after being pushed by Hopkins. He looked at the chart and track on the small screen and found that two thirds of the voyage had gone, and it seemed that there was nothing unusual. Hopkins asked him to pay attention. He heard the voice of a ship sailing on the sea. He had seen it through the sky during the previous voyage. He looked at Hopkins in puzzlement. But after listening, he knew that something was wrong: different from before, the size of the voice did not change this time'\n",
    "print(sample_text)\n",
    "# We'll collect the generated summaries of each model in a dictionary\n",
    "summaries = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2-xl and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'h.12.attn.masked_bias', 'h.13.attn.masked_bias', 'h.14.attn.masked_bias', 'h.15.attn.masked_bias', 'h.16.attn.masked_bias', 'h.17.attn.masked_bias', 'h.18.attn.masked_bias', 'h.19.attn.masked_bias', 'h.20.attn.masked_bias', 'h.21.attn.masked_bias', 'h.22.attn.masked_bias', 'h.23.attn.masked_bias', 'h.24.attn.masked_bias', 'h.25.attn.masked_bias', 'h.26.attn.masked_bias', 'h.27.attn.masked_bias', 'h.28.attn.masked_bias', 'h.29.attn.masked_bias', 'h.30.attn.masked_bias', 'h.31.attn.masked_bias', 'h.32.attn.masked_bias', 'h.33.attn.masked_bias', 'h.34.attn.masked_bias', 'h.35.attn.masked_bias', 'h.36.attn.masked_bias', 'h.37.attn.masked_bias', 'h.38.attn.masked_bias', 'h.39.attn.masked_bias', 'h.40.attn.masked_bias', 'h.41.attn.masked_bias', 'h.42.attn.masked_bias', 'h.43.attn.masked_bias', 'h.44.attn.masked_bias', 'h.45.attn.masked_bias', 'h.46.attn.masked_bias', 'h.47.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Dialogue-Robot\\modules\\basic_summarizer\\notebook\\pegsus.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dialogue-Robot/modules/basic_summarizer/notebook/pegsus.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline, set_seed\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dialogue-Robot/modules/basic_summarizer/notebook/pegsus.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m set_seed(\u001b[39m42\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Dialogue-Robot/modules/basic_summarizer/notebook/pegsus.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pipe \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39;49m\u001b[39mtext-generation\u001b[39;49m\u001b[39m\"\u001b[39;49m, model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt2-xl\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dialogue-Robot/modules/basic_summarizer/notebook/pegsus.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m gpt2_query \u001b[39m=\u001b[39m sample_text \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mTL;DR:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Dialogue-Robot/modules/basic_summarizer/notebook/pegsus.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m pipe_out \u001b[39m=\u001b[39m pipe(gpt2_query, max_length\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m, clean_up_tokenization_spaces\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\pipelines\\__init__.py:381\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, framework, revision, use_fast, **kwargs)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39m# Instantiate modelcard if needed\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(modelcard, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 381\u001b[0m     modelcard \u001b[39m=\u001b[39m ModelCard\u001b[39m.\u001b[39;49mfrom_pretrained(modelcard, revision\u001b[39m=\u001b[39;49mrevision)\n\u001b[0;32m    383\u001b[0m \u001b[39m# Instantiate model if needed\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    385\u001b[0m     \u001b[39m# Handle transparent TF/PT model conversion\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\modelcard.py:155\u001b[0m, in \u001b[0;36mModelCard.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     model_card_file \u001b[39m=\u001b[39m model_card_file\u001b[39m.\u001b[39mreplace(TF2_WEIGHTS_NAME, MODEL_CARD_NAME)\n\u001b[0;32m    153\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m     resolved_model_card_file \u001b[39m=\u001b[39m cached_path(model_card_file, cache_dir\u001b[39m=\u001b[39;49mcache_dir, proxies\u001b[39m=\u001b[39;49mproxies)\n\u001b[0;32m    156\u001b[0m     \u001b[39mif\u001b[39;00m resolved_model_card_file \u001b[39m==\u001b[39m model_card_file:\n\u001b[0;32m    157\u001b[0m         logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mloading model card file \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(model_card_file))\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\file_utils.py:1048\u001b[0m, in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m   1044\u001b[0m     cache_dir \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(cache_dir)\n\u001b[0;32m   1046\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[0;32m   1047\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[1;32m-> 1048\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[0;32m   1049\u001b[0m         url_or_filename,\n\u001b[0;32m   1050\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m   1051\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m   1052\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m   1053\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m   1054\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m   1055\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m   1056\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m   1057\u001b[0m     )\n\u001b[0;32m   1058\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[0;32m   1059\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m     output_path \u001b[39m=\u001b[39m url_or_filename\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\file_utils.py:1234\u001b[0m, in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m   1228\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1229\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mCannot find the requested files in the cached path and outgoing traffic has been\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1230\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m disabled. To enable model look-ups and downloads online, set \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlocal_files_only\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1231\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m to False.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1232\u001b[0m                 )\n\u001b[0;32m   1233\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1234\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1235\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mConnection error, and we cannot find the requested files in the cached path.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1236\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m Please try again or make sure your Internet connection is on.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1237\u001b[0m                 )\n\u001b[0;32m   1239\u001b[0m \u001b[39m# From now on, etag is not None.\u001b[39;00m\n\u001b[0;32m   1240\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(cache_path) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m force_download:\n",
      "\u001b[1;31mValueError\u001b[0m: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on."
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "from transformers import pipeline, set_seed\n",
    "\n",
    "set_seed(42)\n",
    "pipe = pipeline(\"text-generation\", model=\"gpt2-xl\")\n",
    "gpt2_query = sample_text + \"\\nTL;DR:\\n\"\n",
    "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '在海下平静的航程中，沃纳睡着了。不知过了多长时间，他被霍普金斯推醒，他看看小屏幕上的海图和航迹，发现航程已走了三分之二，似乎没有什么异常。霍普金斯让他注意听，他听到了一艘海面航船的声音，在以前的航程中这已司空见贯，他不解地看看霍普金斯。但接着听下去，他知道事情不对：与以前不同，这次声音的大小没有变化。\\nTL;DR:\\n'}]\n"
     ]
    }
   ],
   "source": [
    "print(pipe_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(pipe_out[-1][\"generated_text\"][len(gpt2_query):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries[\"gpt1\"] = \"\\n\".join(\n",
    "    sent_tokenize(pipe_out[-1][\"generated_text\"][len(gpt2_query) :]))\n",
    "# ————————————————\n",
    "# 版权声明：本文为CSDN博主「致Great」的原创文章，遵循CC 3.0 BY-SA版权协议，转载请附上原文出处链接及本声明。\n",
    "# 原文链接：https://blog.csdn.net/yanqianglifei/article/details/124053500"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
