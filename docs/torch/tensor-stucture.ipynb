{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量的操作主要包括张量的结构操作和张量的数学运算。\n",
    "\n",
    "张量结构操作诸如：张量创建，索引切片，维度变换，合并分割，重复。\n",
    "\n",
    "张量数学运算主要有：标量运算，向量运算，矩阵运算。另外我们会介绍张量运算的广播机制。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一、创建张量\n",
    "+ 创建方法类似 numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tmp = [[0,1,3,4], [3,4,5,6]]\n",
    "print(torch.IntTensor(new_tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3],dtype = torch.float)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 3, 5, 7, 9])\n"
     ]
    }
   ],
   "source": [
    "b = torch.arange(1,10,step = 2)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.6978, 1.3956, 2.0933, 2.7911, 3.4889, 4.1867, 4.8844, 5.5822,\n",
      "        6.2800])\n"
     ]
    }
   ],
   "source": [
    "c = torch.linspace(0.0,2*3.14,10)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "d = torch.zeros((3,3))\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((3,3),dtype = torch.int)\n",
    "b = torch.zeros_like(a,dtype = torch.float)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.],\n",
      "        [5., 5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "torch.fill_(b,5)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.9626, 7.6822, 0.8848, 1.3203, 3.0742])\n"
     ]
    }
   ],
   "source": [
    "#均匀随机分布\n",
    "torch.manual_seed(0)\n",
    "minval,maxval = 0,10\n",
    "a = minval + (maxval-minval)*torch.rand([5])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正态分布随机, 均值和标准差来源于 一个 分布\n",
    "b = torch.normal(mean = torch.zeros(3,3), std = torch.ones(3,3))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正态分布随机，均值和标准差 制定\n",
    "mean,std = 2,5\n",
    "c = std*torch.randn((3,3))+mean\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([19,  6,  3,  9,  7, 16,  1, 10, 11, 17,  5,  8,  4,  2, 13, 12,  0, 15,\n",
      "        18, 14])\n"
     ]
    }
   ],
   "source": [
    "#整数随机排列\n",
    "d = torch.randperm(20)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([[11,  0,  0],\n",
      "        [ 0, 22,  0],\n",
      "        [ 0,  0, 33]])\n"
     ]
    }
   ],
   "source": [
    "#特殊矩阵\n",
    "I = torch.eye(3,3) #单位矩阵\n",
    "print(I)\n",
    "t = torch.diag(torch.tensor([11,22,33])) #对角矩阵\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、索引切片\n",
    "+ 张量的索引切片方式和numpy几乎是一样的。切片时支持缺省参数和省略号\n",
    "+ 可以通过索引和切片对部分元素进行修改\n",
    "+ 此外，对于不规则的切片提取,可以使用torch.index_select, torch.masked_select, torch.take\n",
    "+ 如果要通过修改张量的某些元素得到新的张量，可以使用torch.where,torch.masked_fill,torch.index_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 7, 0, 1, 3],\n",
      "        [6, 4, 8, 4, 6],\n",
      "        [3, 4, 0, 1, 2],\n",
      "        [5, 6, 8, 1, 2],\n",
      "        [6, 9, 3, 8, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#均匀随机分布\n",
    "torch.manual_seed(0)\n",
    "minval,maxval = 0,10\n",
    "t = torch.floor(minval + (maxval-minval)*torch.rand([5,5])).int()\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 7, 0, 1, 3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#第0行\n",
    "print(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4, dtype=torch.int32)\n",
      "tensor(4, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#第1行第3列\n",
    "print(t[1,3])\n",
    "print(t[1][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 4, 8, 4, 6],\n",
      "        [3, 4, 0, 1, 2],\n",
      "        [5, 6, 8, 1, 2]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#第1行至第3行\n",
    "print(t[1:4,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 8],\n",
      "        [3, 0],\n",
      "        [5, 8]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#第1行至最后一行，第0列到最后一列每隔两列取一列\n",
    "print(t[1:4,:4:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [0., 0.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#可以使用索引和切片修改部分元素\n",
    "x = torch.tensor([[1,2],[3,4]],dtype = torch.float32,requires_grad=True)\n",
    "x.data[1,:] = torch.tensor([0.0,0.0])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8]],\n",
      "\n",
      "        [[ 9, 10, 11],\n",
      "         [12, 13, 14],\n",
      "         [15, 16, 17]],\n",
      "\n",
      "        [[18, 19, 20],\n",
      "         [21, 22, 23],\n",
      "         [24, 25, 26]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(27).view(3,3,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  4,  7],\n",
      "        [10, 13, 16],\n",
      "        [19, 22, 25]])\n"
     ]
    }
   ],
   "source": [
    "#省略号可以表示多个冒号\n",
    "print(a[...,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上切片方式相对规则，对于不规则的切片提取,可以使用torch.index_select, torch.take, torch.gather, torch.masked_select.\n",
    "\n",
    "考虑班级成绩册的例子，有4个班级，每个班级10个学生，每个学生7门科目成绩。可以用一个4×10×7的张量来表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[55, 95,  3, 18, 37, 30, 93],\n",
      "         [17, 26, 15,  3, 20, 92, 72],\n",
      "         [74, 52, 24, 58,  3, 13, 24],\n",
      "         [81, 79, 27, 48, 81, 99, 69],\n",
      "         [56, 83, 20, 59, 11, 15, 24],\n",
      "         [72, 70, 20, 65, 77, 43, 51],\n",
      "         [61, 81, 98, 11, 31, 69, 91],\n",
      "         [93, 94, 59,  6, 54, 18,  3],\n",
      "         [94, 88,  0, 59, 41, 41, 27],\n",
      "         [69, 20, 68, 75, 85, 68,  0]],\n",
      "\n",
      "        [[17, 74, 60, 10, 21, 97, 83],\n",
      "         [28, 37,  2, 49, 12, 11, 47],\n",
      "         [57, 29, 79, 19, 95, 84,  7],\n",
      "         [37, 52, 57, 61, 69, 52, 25],\n",
      "         [73,  2, 20, 37, 25, 32,  9],\n",
      "         [39, 60, 17, 47, 85, 44, 51],\n",
      "         [45, 60, 81, 97, 81, 97, 46],\n",
      "         [ 5, 26, 84, 49, 25, 11,  3],\n",
      "         [ 7, 39, 77, 77,  1, 81, 10],\n",
      "         [39, 29, 40, 40,  5,  6, 42]],\n",
      "\n",
      "        [[50, 27, 68,  4, 46, 93, 29],\n",
      "         [95, 68,  4, 81, 44, 27, 89],\n",
      "         [ 9, 55, 39, 85, 63, 74, 67],\n",
      "         [37, 39,  8, 77, 89, 84, 14],\n",
      "         [52, 14, 22, 20, 67, 20, 48],\n",
      "         [52, 82, 12, 15, 20, 84, 32],\n",
      "         [92, 68, 56, 49, 40, 56, 38],\n",
      "         [49, 56, 10, 23, 90,  9, 46],\n",
      "         [99, 68, 51,  6, 74, 14, 35],\n",
      "         [33, 42, 50, 91, 56, 94, 80]],\n",
      "\n",
      "        [[18, 72, 14, 28, 64, 66, 87],\n",
      "         [33, 50, 75,  1, 86,  8, 50],\n",
      "         [41, 23, 56, 91, 35, 20, 31],\n",
      "         [ 0, 72, 25, 16, 21, 78, 76],\n",
      "         [88, 68, 33, 36, 64, 91, 63],\n",
      "         [26, 26,  2, 60, 21,  5, 93],\n",
      "         [17, 44, 64, 51, 16,  9, 89],\n",
      "         [58, 91, 33, 64, 38, 47, 19],\n",
      "         [66, 65, 48, 38, 19, 84, 12],\n",
      "         [70, 33, 25, 58, 24, 61, 59]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "minval=0\n",
    "maxval=100\n",
    "scores = torch.floor(minval + (maxval-minval)*torch.rand([4,10,7])).int()\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[55, 95,  3, 18, 37, 30, 93],\n",
       "         [72, 70, 20, 65, 77, 43, 51],\n",
       "         [69, 20, 68, 75, 85, 68,  0]],\n",
       "\n",
       "        [[17, 74, 60, 10, 21, 97, 83],\n",
       "         [39, 60, 17, 47, 85, 44, 51],\n",
       "         [39, 29, 40, 40,  5,  6, 42]],\n",
       "\n",
       "        [[50, 27, 68,  4, 46, 93, 29],\n",
       "         [52, 82, 12, 15, 20, 84, 32],\n",
       "         [33, 42, 50, 91, 56, 94, 80]],\n",
       "\n",
       "        [[18, 72, 14, 28, 64, 66, 87],\n",
       "         [26, 26,  2, 60, 21,  5, 93],\n",
       "         [70, 33, 25, 58, 24, 61, 59]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#抽取每个班级第0个学生，第5个学生，第9个学生的全部成绩\n",
    "torch.index_select(scores,dim = 1,index = torch.tensor([0,5,9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[95, 18, 93],\n",
      "         [70, 65, 51],\n",
      "         [20, 75,  0]],\n",
      "\n",
      "        [[74, 10, 83],\n",
      "         [60, 47, 51],\n",
      "         [29, 40, 42]],\n",
      "\n",
      "        [[27,  4, 29],\n",
      "         [82, 15, 32],\n",
      "         [42, 91, 80]],\n",
      "\n",
      "        [[72, 28, 87],\n",
      "         [26, 60, 93],\n",
      "         [33, 58, 59]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#抽取每个班级第0个学生，第5个学生，第9个学生的第1门课程，第3门课程，第6门课程成绩\n",
    "q = torch.index_select(torch.index_select(scores,dim = 1,index = torch.tensor([0,5,9]))\n",
    "                   ,dim=2,index = torch.tensor([1,3,6]))\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([55, 14, 59], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#抽取第0个班级第0个学生的第0门课程，第2个班级的第4个学生的第1门课程，第3个班级的第9个学生第6门课程成绩\n",
    "#take将输入看成一维数组，输出和index同形状\n",
    "s = torch.take(scores,torch.tensor([0*10*7+0,2*10*7+4*7+1,3*10*7+9*7+6]))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([95, 93, 92, 81, 81, 99, 83, 81, 98, 91, 93, 94, 94, 88, 85, 97, 83, 95,\n",
      "        84, 85, 81, 97, 81, 97, 84, 81, 93, 95, 81, 89, 85, 89, 84, 82, 84, 92,\n",
      "        90, 99, 91, 94, 80, 87, 86, 91, 88, 91, 93, 89, 91, 84],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#抽取分数大于等于80分的分数（布尔索引）\n",
    "#结果是1维张量\n",
    "g = torch.masked_select(scores, scores>=80)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上这些方法仅能提取张量的部分元素值，但不能更改张量的部分元素值得到新的张量。\n",
    "\n",
    "如果要通过修改张量的部分元素值得到新的张量，可以使用torch.where,torch.index_fill 和 torch.masked_fill\n",
    "\n",
    "torch.where可以理解为if的张量版本。\n",
    "\n",
    "torch.index_fill的选取元素逻辑和torch.index_select相同。\n",
    "\n",
    "torch.masked_fill的选取元素逻辑和torch.masked_select相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 0, 0, 0, 0, 1],\n",
      "         [0, 0, 0, 0, 0, 1, 1],\n",
      "         [1, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 1, 0, 0, 1, 1, 1],\n",
      "         [0, 1, 0, 0, 0, 0, 0],\n",
      "         [1, 1, 0, 1, 1, 0, 0],\n",
      "         [1, 1, 1, 0, 0, 1, 1],\n",
      "         [1, 1, 0, 0, 0, 0, 0],\n",
      "         [1, 1, 0, 0, 0, 0, 0],\n",
      "         [1, 0, 1, 1, 1, 1, 0]],\n",
      "\n",
      "        [[0, 1, 0, 0, 0, 1, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 1, 0, 1, 1, 0],\n",
      "         [0, 0, 0, 1, 1, 0, 0],\n",
      "         [1, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 1, 0, 0],\n",
      "         [0, 0, 1, 1, 1, 1, 0],\n",
      "         [0, 0, 1, 0, 0, 0, 0],\n",
      "         [0, 0, 1, 1, 0, 1, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 1, 0, 0, 1, 0],\n",
      "         [1, 1, 0, 1, 0, 0, 1],\n",
      "         [0, 0, 0, 1, 1, 1, 1],\n",
      "         [0, 0, 0, 1, 1, 1, 0],\n",
      "         [0, 0, 0, 0, 1, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 1, 0],\n",
      "         [1, 1, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 1, 0, 0],\n",
      "         [1, 1, 0, 0, 1, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 1, 1]],\n",
      "\n",
      "        [[0, 1, 0, 0, 1, 1, 1],\n",
      "         [0, 0, 1, 0, 1, 0, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 1, 1],\n",
      "         [1, 1, 0, 0, 1, 1, 1],\n",
      "         [0, 0, 0, 0, 0, 0, 1],\n",
      "         [0, 0, 1, 0, 0, 0, 1],\n",
      "         [0, 1, 0, 1, 0, 0, 0],\n",
      "         [1, 1, 0, 0, 0, 1, 0],\n",
      "         [1, 0, 0, 0, 0, 1, 0]]])\n"
     ]
    }
   ],
   "source": [
    "#如果分数大于60分，赋值成1，否则赋值成0\n",
    "ifpass = torch.where(scores>60,torch.tensor(1),torch.tensor(0))\n",
    "print(ifpass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[100, 100, 100, 100, 100, 100, 100],\n",
       "         [ 17,  26,  15,   3,  20,  92,  72],\n",
       "         [ 74,  52,  24,  58,   3,  13,  24],\n",
       "         [ 81,  79,  27,  48,  81,  99,  69],\n",
       "         [ 56,  83,  20,  59,  11,  15,  24],\n",
       "         [100, 100, 100, 100, 100, 100, 100],\n",
       "         [ 61,  81,  98,  11,  31,  69,  91],\n",
       "         [ 93,  94,  59,   6,  54,  18,   3],\n",
       "         [ 94,  88,   0,  59,  41,  41,  27],\n",
       "         [100, 100, 100, 100, 100, 100, 100]],\n",
       "\n",
       "        [[100, 100, 100, 100, 100, 100, 100],\n",
       "         [ 28,  37,   2,  49,  12,  11,  47],\n",
       "         [ 57,  29,  79,  19,  95,  84,   7],\n",
       "         [ 37,  52,  57,  61,  69,  52,  25],\n",
       "         [ 73,   2,  20,  37,  25,  32,   9],\n",
       "         [100, 100, 100, 100, 100, 100, 100],\n",
       "         [ 45,  60,  81,  97,  81,  97,  46],\n",
       "         [  5,  26,  84,  49,  25,  11,   3],\n",
       "         [  7,  39,  77,  77,   1,  81,  10],\n",
       "         [100, 100, 100, 100, 100, 100, 100]],\n",
       "\n",
       "        [[100, 100, 100, 100, 100, 100, 100],\n",
       "         [ 95,  68,   4,  81,  44,  27,  89],\n",
       "         [  9,  55,  39,  85,  63,  74,  67],\n",
       "         [ 37,  39,   8,  77,  89,  84,  14],\n",
       "         [ 52,  14,  22,  20,  67,  20,  48],\n",
       "         [100, 100, 100, 100, 100, 100, 100],\n",
       "         [ 92,  68,  56,  49,  40,  56,  38],\n",
       "         [ 49,  56,  10,  23,  90,   9,  46],\n",
       "         [ 99,  68,  51,   6,  74,  14,  35],\n",
       "         [100, 100, 100, 100, 100, 100, 100]],\n",
       "\n",
       "        [[100, 100, 100, 100, 100, 100, 100],\n",
       "         [ 33,  50,  75,   1,  86,   8,  50],\n",
       "         [ 41,  23,  56,  91,  35,  20,  31],\n",
       "         [  0,  72,  25,  16,  21,  78,  76],\n",
       "         [ 88,  68,  33,  36,  64,  91,  63],\n",
       "         [100, 100, 100, 100, 100, 100, 100],\n",
       "         [ 17,  44,  64,  51,  16,   9,  89],\n",
       "         [ 58,  91,  33,  64,  38,  47,  19],\n",
       "         [ 66,  65,  48,  38,  19,  84,  12],\n",
       "         [100, 100, 100, 100, 100, 100, 100]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将每个班级第0个学生，第5个学生，第9个学生的全部成绩赋值成满分\n",
    "torch.index_fill(scores,dim = 1,index = torch.tensor([0,5,9]),value = 100)\n",
    "#等价于 scores.index_fill(dim = 1,index = torch.tensor([0,5,9]),value = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[60, 95, 60, 60, 60, 60, 93],\n",
      "         [60, 60, 60, 60, 60, 92, 72],\n",
      "         [74, 60, 60, 60, 60, 60, 60],\n",
      "         [81, 79, 60, 60, 81, 99, 69],\n",
      "         [60, 83, 60, 60, 60, 60, 60],\n",
      "         [72, 70, 60, 65, 77, 60, 60],\n",
      "         [61, 81, 98, 60, 60, 69, 91],\n",
      "         [93, 94, 60, 60, 60, 60, 60],\n",
      "         [94, 88, 60, 60, 60, 60, 60],\n",
      "         [69, 60, 68, 75, 85, 68, 60]],\n",
      "\n",
      "        [[60, 74, 60, 60, 60, 97, 83],\n",
      "         [60, 60, 60, 60, 60, 60, 60],\n",
      "         [60, 60, 79, 60, 95, 84, 60],\n",
      "         [60, 60, 60, 61, 69, 60, 60],\n",
      "         [73, 60, 60, 60, 60, 60, 60],\n",
      "         [60, 60, 60, 60, 85, 60, 60],\n",
      "         [60, 60, 81, 97, 81, 97, 60],\n",
      "         [60, 60, 84, 60, 60, 60, 60],\n",
      "         [60, 60, 77, 77, 60, 81, 60],\n",
      "         [60, 60, 60, 60, 60, 60, 60]],\n",
      "\n",
      "        [[60, 60, 68, 60, 60, 93, 60],\n",
      "         [95, 68, 60, 81, 60, 60, 89],\n",
      "         [60, 60, 60, 85, 63, 74, 67],\n",
      "         [60, 60, 60, 77, 89, 84, 60],\n",
      "         [60, 60, 60, 60, 67, 60, 60],\n",
      "         [60, 82, 60, 60, 60, 84, 60],\n",
      "         [92, 68, 60, 60, 60, 60, 60],\n",
      "         [60, 60, 60, 60, 90, 60, 60],\n",
      "         [99, 68, 60, 60, 74, 60, 60],\n",
      "         [60, 60, 60, 91, 60, 94, 80]],\n",
      "\n",
      "        [[60, 72, 60, 60, 64, 66, 87],\n",
      "         [60, 60, 75, 60, 86, 60, 60],\n",
      "         [60, 60, 60, 91, 60, 60, 60],\n",
      "         [60, 72, 60, 60, 60, 78, 76],\n",
      "         [88, 68, 60, 60, 64, 91, 63],\n",
      "         [60, 60, 60, 60, 60, 60, 93],\n",
      "         [60, 60, 64, 60, 60, 60, 89],\n",
      "         [60, 91, 60, 64, 60, 60, 60],\n",
      "         [66, 65, 60, 60, 60, 84, 60],\n",
      "         [70, 60, 60, 60, 60, 61, 60]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "#将分数小于60分的分数赋值成60分\n",
    "b = torch.masked_fill(scores,scores<60,60)\n",
    "#等价于b = scores.masked_fill(scores<60,60)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、维度变换\n",
    "\n",
    "维度变换相关函数主要有 torch.reshape(或者调用张量的view方法), torch.squeeze, torch.unsqueeze, torch.transpose\n",
    "\n",
    "torch.reshape 可以改变张量的形状。\n",
    "\n",
    "torch.squeeze 可以减少维度。\n",
    "\n",
    "torch.unsqueeze 可以增加维度。\n",
    "\n",
    "torch.transpose 可以交换维度。\n",
    "\n",
    "torch.permute \n",
    "+ transpose 和 permute 的区别 https://blog.csdn.net/xinjieyuan/article/details/105232802"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3, 2])\n",
      "tensor([[[[126, 195],\n",
      "          [ 22,  33],\n",
      "          [ 78, 161]],\n",
      "\n",
      "         [[124, 228],\n",
      "          [116, 161],\n",
      "          [ 88, 102]],\n",
      "\n",
      "         [[  5,  43],\n",
      "          [ 74, 132],\n",
      "          [177, 204]]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 张量的view方法有时候会调用失败，可以使用reshape方法。\n",
    "\n",
    "torch.manual_seed(0)\n",
    "minval,maxval = 0,255\n",
    "a = (minval + (maxval-minval)*torch.rand([1,3,3,2])).int()\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 6])\n",
      "tensor([[126, 195,  22,  33,  78, 161],\n",
      "        [124, 228, 116, 161,  88, 102],\n",
      "        [  5,  43,  74, 132, 177, 204]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 改成 （3,6）形状的张量\n",
    "b = a.view([3,6]) #torch.reshape(a,[3,6])\n",
    "print(b.shape)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改回成 [1,3,3,2] 形状的张量\n",
    "c = torch.reshape(b,[1,3,3,2]) # b.view([1,3,3,2]) \n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果张量在某个维度上只有一个元素，利用torch.squeeze可以消除这个维度\n",
    "\n",
    "torch.unsqueeze的作用和torch.squeeze的作用相反"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.]])\n",
      "tensor([1., 2.])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1.0,2.0]])\n",
    "s = torch.squeeze(a)\n",
    "print(a)\n",
    "print(s)\n",
    "print(a.shape)\n",
    "print(s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.])\n",
      "tensor([[1., 2.]])\n",
      "torch.Size([2])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "#在第0维插入长度为1的一个维度\n",
    "\n",
    "d = torch.unsqueeze(s,axis=0)  \n",
    "print(s)\n",
    "print(d)\n",
    "\n",
    "print(s.shape)\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.transpose可以交换张量的维度，torch.transpose常用于图片存储格式的变换上。\n",
    "\n",
    "如果是二维的矩阵，通常会调用矩阵的转置方法 matrix.t()，等价于 torch.transpose(matrix,0,1)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 256, 256, 4])\n",
      "torch.Size([100, 4, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "minval=0\n",
    "maxval=255\n",
    "# Batch,Height,Width,Channel\n",
    "data = torch.floor(minval + (maxval-minval)*torch.rand([100,256,256,4])).int()\n",
    "print(data.shape)\n",
    "\n",
    "# 转换成 Pytorch默认的图片格式 Batch,Channel,Height,Width \n",
    "# 需要交换两次\n",
    "data_t = torch.transpose(torch.transpose(data,1,2),1,3)\n",
    "print(data_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "matrix = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(matrix)\n",
    "print(matrix.t()) #等价于torch.transpose(matrix,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四，合并分割\n",
    "\n",
    "可以用torch.cat方法和torch.stack方法将多个张量合并，可以用torch.split方法把一个张量分割成多个张量。\n",
    "\n",
    "torch.cat和torch.stack有略微的区别，torch.cat是连接，不会增加维度，而torch.stack是堆叠，会增加维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2])\n",
      "tensor([[ 1.,  2.],\n",
      "        [ 3.,  4.],\n",
      "        [ 5.,  6.],\n",
      "        [ 7.,  8.],\n",
      "        [ 9., 10.],\n",
      "        [11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1.0,2.0],[3.0,4.0]])\n",
    "b = torch.tensor([[5.0,6.0],[7.0,8.0]])\n",
    "c = torch.tensor([[9.0,10.0],[11.0,12.0]])\n",
    "\n",
    "abc_cat = torch.cat([a,b,c],dim = 0)\n",
    "print(abc_cat.shape)\n",
    "print(abc_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 2])\n",
      "tensor([[[ 1.,  2.],\n",
      "         [ 3.,  4.]],\n",
      "\n",
      "        [[ 5.,  6.],\n",
      "         [ 7.,  8.]],\n",
      "\n",
      "        [[ 9., 10.],\n",
      "         [11., 12.]]])\n"
     ]
    }
   ],
   "source": [
    "abc_stack = torch.stack([a,b,c],axis = 0) #torch中dim和axis参数名可以混用\n",
    "print(abc_stack.shape)\n",
    "print(abc_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  5.,  6.,  9., 10.],\n",
       "        [ 3.,  4.,  7.,  8., 11., 12.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a,b,c],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.],\n",
       "         [ 5.,  6.],\n",
       "         [ 9., 10.]],\n",
       "\n",
       "        [[ 3.,  4.],\n",
       "         [ 7.,  8.],\n",
       "         [11., 12.]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([a,b,c],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.split是torch.cat的逆运算，可以指定分割份数平均分割，也可以通过指定每份的记录数量进行分割。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.],\n",
      "        [ 3.,  4.],\n",
      "        [ 5.,  6.],\n",
      "        [ 7.,  8.],\n",
      "        [ 9., 10.],\n",
      "        [11., 12.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[5., 6.],\n",
      "        [7., 8.]])\n",
      "tensor([[ 9., 10.],\n",
      "        [11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "print(abc_cat)\n",
    "a,b,c = torch.split(abc_cat,split_size_or_sections = 2,dim = 0) #每份2个进行分割\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.],\n",
      "        [ 3.,  4.],\n",
      "        [ 5.,  6.],\n",
      "        [ 7.,  8.],\n",
      "        [ 9., 10.],\n",
      "        [11., 12.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.],\n",
      "        [7., 8.]])\n",
      "tensor([[ 9., 10.]])\n",
      "tensor([[11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "print(abc_cat)\n",
    "p,q,r = torch.split(abc_cat,split_size_or_sections =[4,1,1],dim = 0) #每份分别为[4,1,1]\n",
    "print(p)\n",
    "print(q)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五 重复\n",
    "+ repeat \n",
    "+ tile\n",
    "  + input(Tensor) -要重复其元素的张量\n",
    "  + dims(tuple) -每个维度的重复次数\n",
    "+ ger \n",
    "  + https://blog.csdn.net/qq_36516958/article/details/114703215\n",
    "  + torch.ger这个函数是对tensor进行扩维，torch.ger(a,b)实际意思是b中的每一个元素乘以a中的元素，进行扩维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1,2,3])\n",
    "\n",
    "#将一维度的x扩展到三维\n",
    "xx = x.repeat(4,2,1)\n",
    "\n",
    "print(xx)\n",
    "\n",
    "# /**\n",
    "# 扩展步骤如下(倒着执行)：\n",
    "# 1  最后一个维度1：此时将[1,2,3]中的数字直接重复1次，得到[1,2,3]，保持没变\n",
    "# 2  倒数第二个维度2：先将上一步骤的结果增加一个维度，得到[[1,2,3]]，然后将最外层中括号中的整体重复2次，得到[[1,2,3],[1,2,3]]\n",
    "# 3  倒数第三个维度4：先将上一步骤的结果增加一个维度，得到[[[1,2,3],[1,2,3]]]，然后将最外层中括号中的整体重复4次，得到[[[1,2,3],[1,2,3]],[[1,2,3],[1,2,3]],[[1,2,3],[1,2,3]],[[1,2,3],[1,2,3]]]\n",
    "# 4  三个维度扩展结束，得到结果。\n",
    "\n",
    "# **/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x.tile((2,))\n",
    "y = torch.tensor([[1, 2], [3, 4]])\n",
    "torch.tile(y, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "v1 = torch.arange(1., 5.)\n",
    "v2 = torch.arange(1., 4.)\n",
    "print(torch.outer(v1, v2))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d20345af9713ebff8c68be7a4bc786792663d50f698c1c39eb248438a08adbaa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
